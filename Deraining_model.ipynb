{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deraining_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBoali8oot2"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiadsMKJjEal"
      },
      "source": [
        "import os\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.utils.data as Data\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "from torchvision.models.vgg import vgg16\r\n",
        "from tensorboardX import SummaryWriter\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "import pylab\r\n",
        "from skimage.measure import compare_psnr, compare_ssim\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NJopB3wmsHr"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LstxtgMrmVag"
      },
      "source": [
        "class RainDataset(Dataset):\r\n",
        "    def __init__(self, opt):\r\n",
        "        super(RainDataset, self).__init__()\r\n",
        "        self.dataset=opt\r\n",
        "        self.img_list = sorted(glob.glob(self.dataset+'/data/*'))\r\n",
        "        self.gt_list = sorted(glob.glob(self.dataset+'/gt/*'))\r\n",
        "   \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.img_list)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        img_name = self.img_list[idx]\r\n",
        "        gt_name = self.gt_list[idx]\r\n",
        "\r\n",
        "        img = cv2.imread(img_name,-1)\r\n",
        "        gt = cv2.imread(gt_name,-1)\r\n",
        "\r\n",
        "        img = cv2.resize(img, (224,224), interpolation=cv2.INTER_AREA)\r\n",
        "        gt = cv2.resize(gt, (224,224), interpolation=cv2.INTER_AREA)\r\n",
        "        # img = np.asarray(img).transpose((2,0,1))\r\n",
        "        # gt = np.asarray(gt).transpose((2,0,1))\r\n",
        "\r\n",
        "        if img.dtype == np.uint8:\r\n",
        "            img = (img / 255.0).astype('float32')\r\n",
        "        if gt.dtype == np.uint8:\r\n",
        "            gt = (gt / 255.0).astype('float32')\r\n",
        "\r\n",
        "        return [img,gt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIkkVHdGnN8e"
      },
      "source": [
        "!gdown --id 1FaQ0U6NPwQr5MKdHaf7419XEaYDJDYdi --output train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk5LUGxjznqJ"
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y-QLsDq1KBl"
      },
      "source": [
        "train_dataset=RainDataset('train/')\r\n",
        "valid_dataset=RainDataset('test_a/')\r\n",
        "#test_dataset=RainDataset('test_b/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T1DHXkf8M1I"
      },
      "source": [
        "batch_size=1\r\n",
        "lr=0.0002\r\n",
        "iter=200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky9V1T2e7SmW"
      },
      "source": [
        "train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "valid_loader=DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOH_YUe8bFJ",
        "outputId": "d720783d-3610-4979-9666-2aa55b6c0d03"
      },
      "source": [
        "len(train_loader),len(valid_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(861, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOzsn7AwEyvQ"
      },
      "source": [
        "ITERATION = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsjlQy1ZEm3G"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        self.det_conv0 = nn.Sequential(\r\n",
        "            nn.Conv2d(4, 32, 3, 1, 1),\r\n",
        "            nn.ReLU() # LeakyReLU(0.2)\r\n",
        "            )\r\n",
        "        self.det_conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.det_conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.det_conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.det_conv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.det_conv5 = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv_i = nn.Sequential(\r\n",
        "            nn.Conv2d(32 + 32, 32, 3, 1, 1),\r\n",
        "            nn.Sigmoid()\r\n",
        "            )\r\n",
        "        self.conv_f = nn.Sequential(\r\n",
        "            nn.Conv2d(32 + 32, 32, 3, 1, 1),\r\n",
        "            nn.Sigmoid()\r\n",
        "            )\r\n",
        "        self.conv_g = nn.Sequential(\r\n",
        "            nn.Conv2d(32 + 32, 32, 3, 1, 1),\r\n",
        "            nn.Tanh()\r\n",
        "            )\r\n",
        "        self.conv_o = nn.Sequential(\r\n",
        "            nn.Conv2d(32 + 32, 32, 3, 1, 1),\r\n",
        "            nn.Sigmoid()\r\n",
        "            )\r\n",
        "        self.det_conv_mask = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 1, 3, 1, 1),\r\n",
        "            )\r\n",
        "        self.conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(4, 64, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 128, 3, 2, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 256, 3, 2, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv5 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv6 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.diconv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 2, dilation = 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.diconv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 4, dilation = 4),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.diconv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 8, dilation = 8),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.diconv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 16, dilation = 16),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv7 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv8 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.deconv1 = nn.Sequential(\r\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\r\n",
        "            nn.ReflectionPad2d((1, 0, 1, 0)),\r\n",
        "            nn.AvgPool2d(2, stride = 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv9 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.deconv2 = nn.Sequential(\r\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\r\n",
        "            nn.ReflectionPad2d((1, 0, 1, 0)),\r\n",
        "            nn.AvgPool2d(2, stride = 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv10 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 32, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.outframe1 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 3, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.outframe2 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 3, 3, 1, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.output = nn.Sequential(\r\n",
        "            nn.Conv2d(32, 3, 3, 1, 1)\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        batch_size, row, col = input.size(0), input.size(2), input.size(3)\r\n",
        "        mask = Variable(torch.ones(batch_size, 1, row, col)).to(device) / 2.\r\n",
        "        h = Variable(torch.zeros(batch_size, 32, row, col)).to(device) \r\n",
        "        c = Variable(torch.zeros(batch_size, 32, row, col)).to(device)\r\n",
        "        mask_list = []\r\n",
        "        for i in range(ITERATION):\r\n",
        "            x = torch.cat((input, mask), 1)\r\n",
        "            x = self.det_conv0(x)\r\n",
        "            resx = x\r\n",
        "            x = F.relu(self.det_conv1(x) + resx)  ## ResNet Block - > Pre Activation 구조로 변형해보기\r\n",
        "            resx = x\r\n",
        "            x = F.relu(self.det_conv2(x) + resx)\r\n",
        "            resx = x\r\n",
        "            x = F.relu(self.det_conv3(x) + resx)\r\n",
        "            resx = x\r\n",
        "            x = F.relu(self.det_conv4(x) + resx)\r\n",
        "            resx = x\r\n",
        "            x = F.relu(self.det_conv5(x) + resx)\r\n",
        "            x = torch.cat((x, h), 1)\r\n",
        "            i = self.conv_i(x)\r\n",
        "            f = self.conv_f(x)\r\n",
        "            g = self.conv_g(x)\r\n",
        "            o = self.conv_o(x)\r\n",
        "            c = f * c + i * g\r\n",
        "            h = o * torch.tanh(c)\r\n",
        "            mask = self.det_conv_mask(h)\r\n",
        "            mask_list.append(mask)\r\n",
        "        x = torch.cat((input, mask), 1)\r\n",
        "        x = self.conv1(x)\r\n",
        "        res1 = x\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "        res2 = x\r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.conv6(x)\r\n",
        "        x = self.diconv1(x)\r\n",
        "        x = self.diconv2(x)\r\n",
        "        x = self.diconv3(x)\r\n",
        "        x = self.diconv4(x)\r\n",
        "        x = self.conv7(x)\r\n",
        "        x = self.conv8(x)\r\n",
        "        frame1 = self.outframe1(x)\r\n",
        "        x = self.deconv1(x)\r\n",
        "        x = x + res2\r\n",
        "        x = self.conv9(x)\r\n",
        "        frame2 = self.outframe2(x)\r\n",
        "        x = self.deconv2(x)\r\n",
        "        x = x + res1\r\n",
        "        x = self.conv10(x)\r\n",
        "        x = self.output(x)\r\n",
        "        return mask_list, frame1, frame2, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiCFFzcGFJuh"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        self.conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 8, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(8, 16, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(16, 64, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 128, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv5 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 128, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv6 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 128, 5, 1, 2),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv_mask = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 1, 5, 1, 2)\r\n",
        "            )\r\n",
        "        self.conv7 = nn.Sequential(\r\n",
        "            nn.Conv2d(128, 64, 5, 4, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.conv8 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 32, 5, 4, 1),\r\n",
        "            nn.ReLU()\r\n",
        "            )\r\n",
        "        self.fc = nn.Sequential(\r\n",
        "            nn.Linear(32 * 14 * 14, 1024),\r\n",
        "            nn.Linear(1024, 1),\r\n",
        "            nn.Sigmoid()\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.conv6(x)\r\n",
        "        mask = self.conv_mask(x)\r\n",
        "        x = self.conv7(x * mask)\r\n",
        "        # x = self.conv7(x)\r\n",
        "        # print 7, x.shape\r\n",
        "        x = self.conv8(x)\r\n",
        "        x=x.reshape(x.size(0), -1)\r\n",
        "        return [mask, self.fc(x)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8mELAC6Nu4"
      },
      "source": [
        "def trainable(net, trainable):\r\n",
        "    for para in net.parameters():\r\n",
        "        para.requires_grad = trainable\r\n",
        "\r\n",
        "#Initialize VGG16 with pretrained weight on ImageNet\r\n",
        "def vgg_init():\r\n",
        "    vgg_model = vgg16(pretrained = True).to(device)\r\n",
        "    trainable(vgg_model, False)\r\n",
        "    return vgg_model\r\n",
        "\r\n",
        "class vgg(nn.Module):\r\n",
        "    def __init__(self, vgg_model):\r\n",
        "        super(vgg, self).__init__()\r\n",
        "        self.vgg_layers = vgg_model.features\r\n",
        "        self.layer_name_mapping = {\r\n",
        "            '1': \"relu1_1\",\r\n",
        "            '3': \"relu1_2\",\r\n",
        "            '6': \"relu2_1\",\r\n",
        "            '8': \"relu2_2\"\r\n",
        "        }\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        output = []\r\n",
        "        for name, module in self.vgg_layers._modules.items():\r\n",
        "            x = module(x)\r\n",
        "            if name in self.layer_name_mapping:\r\n",
        "                output.append(x)\r\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsFt2h-aARbJ"
      },
      "source": [
        "def torch_variable(x,is_train):\r\n",
        "  if is_train:\r\n",
        "    return Variable(torch.from_numpy(np.array(x).transpose((0,3,1,2))),requires_grad=True).to(device)\r\n",
        "  else:\r\n",
        "    with torch.no_grad():\r\n",
        "      result=torch.from_numpy(np.array(x).transpose((0,3,1,2))).to(device)\r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpj-KBLA9Csz"
      },
      "source": [
        "def get_mask(dg_img,img):\r\n",
        "\t# downgraded image - image\r\n",
        "\tmask = np.fabs(dg_img-img)\r\n",
        "\t# threshold under 30\r\n",
        "\tmask[np.where(mask<(30.0/255.0))] = 0.0\r\n",
        "\tmask[np.where(mask>0.0)] = 1.0\r\n",
        "\t#avg? max?\r\n",
        "\t# mask = np.average(mask, axis=2)\r\n",
        "\tmask = np.max(mask, axis=2)\r\n",
        "\tmask = np.expand_dims(mask, axis=2)\r\n",
        "\treturn mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GQ6vLa7hGNT"
      },
      "source": [
        "def calc_psnr(im1, im2):\r\n",
        "    im1_y = cv2.cvtColor(im1, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\r\n",
        "    im2_y = cv2.cvtColor(im2, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\r\n",
        "    return compare_psnr(im1_y, im2_y)\r\n",
        "\r\n",
        "def calc_ssim(im1, im2):\r\n",
        "    im1_y = cv2.cvtColor(im1, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\r\n",
        "    im2_y = cv2.cvtColor(im2, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\r\n",
        "    return compare_ssim(im1_y, im2_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY6JjuZ4pn04"
      },
      "source": [
        "def align_to_four(img):\r\n",
        "  a_row=int(img.shape[0]/4)*4\r\n",
        "  a_col=int(img.shape[1]/4)*4\r\n",
        "  img=img[0:a_row,0:a_col]\r\n",
        "  return img\r\n",
        "\r\n",
        "def predict(image,model):\r\n",
        "  image=image.transpose((2,0,1))\r\n",
        "  image=image[np.newaxis,:,:,:]\r\n",
        "  image=torch.from_numpy(image)\r\n",
        "  image=Variable(image).to(device)\r\n",
        "\r\n",
        "  out=model(image)[-1]\r\n",
        "  out=out.cpu().data\r\n",
        "  out=out.numpy()\r\n",
        "  out=out.transpose((0,2,3,1))\r\n",
        "  out=out[0,:,:,:]*255.\r\n",
        "\r\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGC03tVrNmm0"
      },
      "source": [
        "def minmax_scale(input_arr):\r\n",
        "    \"\"\"\r\n",
        "    :param input_arr:\r\n",
        "    :return:\r\n",
        "    \"\"\"\r\n",
        "    min_val = np.min(input_arr)\r\n",
        "    max_val = np.max(input_arr)\r\n",
        "\r\n",
        "    output_arr = (input_arr - min_val) / (max_val - min_val)\r\n",
        "\r\n",
        "    return output_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVWLHoRw-Srr"
      },
      "source": [
        "class GANLoss(nn.Module):\r\n",
        "    def __init__(self, real_label=1.0, fake_label=0.0):\r\n",
        "        super(GANLoss, self).__init__()\r\n",
        "        self.real_label = real_label\r\n",
        "        self.fake_label = fake_label\r\n",
        "        self.loss = nn.BCELoss().to(device)\r\n",
        "    def convert_tensor(self, input, is_real):\r\n",
        "        if is_real:\r\n",
        "            return Variable(torch.FloatTensor(input.size()).fill_(self.real_label)).to(device)\r\n",
        "        else:\r\n",
        "            return Variable(torch.FloatTensor(input.size()).fill_(self.fake_label)).to(device) \r\n",
        "    def __call__(self, input, is_real):\r\n",
        "        return self.loss(input, self.convert_tensor(input,is_real).to(device))\r\n",
        "\r\n",
        "class AttentionLoss(nn.Module):\r\n",
        "    def __init__(self, theta=0.8, iteration=4):\r\n",
        "        super(AttentionLoss, self).__init__()\r\n",
        "        self.theta = theta\r\n",
        "        self.iteration = iteration\r\n",
        "        self.loss = nn.MSELoss().to(device)\r\n",
        "\r\n",
        "    def __call__(self, A_, M_):\r\n",
        "        loss_ATT = None\r\n",
        "        for i in range(1, self.iteration+1):\r\n",
        "            if i == 1:\r\n",
        "                loss_ATT = pow(self.theta, float(self.iteration-i)) * self.loss(A_[i-1],M_)\r\n",
        "            else:\r\n",
        "                loss_ATT += pow(self.theta, float(self.iteration-i)) * self.loss(A_[i-1],M_)\r\n",
        "        return loss_ATT\r\n",
        "\r\n",
        "# VGG16 pretrained on Imagenet\r\n",
        "def trainable_(net, trainable):\r\n",
        "    for param in net.parameters():\r\n",
        "        param.requires_grad = trainable\r\n",
        "\r\n",
        "class PerceptualLoss(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(PerceptualLoss, self).__init__()\r\n",
        "        self.model = (vgg16(pretrained = True).to(device))\r\n",
        "        trainable_(self.model, False)\r\n",
        "\r\n",
        "        self.loss = nn.MSELoss().to(device)\r\n",
        "        self.vgg_layers = self.model.features\r\n",
        "        self.layer_name_mapping = {\r\n",
        "            '1': \"relu1_1\",\r\n",
        "            '3': \"relu1_2\",\r\n",
        "            '6': \"relu2_1\",\r\n",
        "            '8': \"relu2_2\"\r\n",
        "        }\r\n",
        "    def get_layer_output(self,x):\r\n",
        "      with torch.no_grad():\r\n",
        "        output = []\r\n",
        "        for name, module in self.vgg_layers._modules.items():\r\n",
        "            x = module(x)\r\n",
        "            if name in self.layer_name_mapping:\r\n",
        "                output.append(x)\r\n",
        "      return output\r\n",
        "\r\n",
        "    def __call__(self, O_, T_):\r\n",
        "        o = self.get_layer_output(O_)\r\n",
        "        t = self.get_layer_output(T_)\r\n",
        "        loss_PL = None\r\n",
        "        for i in range(len(t)):\r\n",
        "            if i == 0:\r\n",
        "                loss_PL = self.loss(o[i],t[i]) \r\n",
        "            else:\r\n",
        "                loss_PL += self.loss(o[i],t[i])\r\n",
        "\r\n",
        "        loss_PL=loss_PL/float(len(t))        \r\n",
        "        loss_PL = Variable(loss_PL,requires_grad=True)\r\n",
        "        return loss_PL\r\n",
        "        \r\n",
        "class MultiscaleLoss(nn.Module):\r\n",
        "    def __init__(self, ld=[ 0.6 , 0.8 , 1.0], batch=1):\r\n",
        "        super(MultiscaleLoss, self).__init__()\r\n",
        "        self.loss = nn.MSELoss().to(device)\r\n",
        "        self.ld = ld\r\n",
        "        self.batch=batch\r\n",
        "    def __call__(self, S_, gt):\r\n",
        "        #1,128,256,3\r\n",
        "        T_ = []\r\n",
        "        #print('S_[0]의 shape[0] : %d',%(S_[0].shape[0])) \r\n",
        "        for i in range(S_[0].shape[0]):\r\n",
        "            temp = []\r\n",
        "            x = (np.array(gt[i])*255.).astype(np.uint8)\r\n",
        "            # print (x.shape, x.dtype)\r\n",
        "            t = cv2.resize(x, None, fx=1.0/4.0,fy=1.0/4.0, interpolation=cv2.INTER_AREA)\r\n",
        "            t = np.expand_dims((t/255.).astype(np.float32).transpose(2,0,1),axis=0)\r\n",
        "            temp.append(t)\r\n",
        "            t = cv2.resize(x, None, fx=1.0/2.0,fy=1.0/2.0, interpolation=cv2.INTER_AREA)\r\n",
        "            t = np.expand_dims((t/255.).astype(np.float32).transpose(2,0,1),axis=0)\r\n",
        "            temp.append(t)\r\n",
        "            x = np.expand_dims((x/255.).astype(np.float32).transpose(2,0,1),axis=0)\r\n",
        "            temp.append(x)\r\n",
        "            T_.append(temp)\r\n",
        "        temp_T = []\r\n",
        "        for i in range(len(self.ld)):\r\n",
        "            # if self.batch == 1:\r\n",
        "            #     temp_T.append(Variable(torch.from_numpy(T_[0][i])).to(device))\r\n",
        "            # else:\r\n",
        "            for j in range((S_[0].shape[0])):\r\n",
        "                if j == 0:\r\n",
        "                    x = T_[j][i]\r\n",
        "                else:\r\n",
        "                    x = np.concatenate((x, T_[j][i]), axis=0)\r\n",
        "            temp_T.append(Variable(torch.from_numpy(x)).to(device))\r\n",
        "        T_ = temp_T\r\n",
        "        loss_ML = None\r\n",
        "        for i in range(len(self.ld)):\r\n",
        "            if i == 0: \r\n",
        "                loss_ML = self.ld[i] * self.loss(S_[i], T_[i])\r\n",
        "            else:\r\n",
        "                loss_ML += self.ld[i] * self.loss(S_[i], T_[i])\r\n",
        "        \r\n",
        "        return loss_ML/float(S_[0].shape[0])\r\n",
        "\r\n",
        "class MAPLoss(nn.Module):\r\n",
        "    def __init__(self, gamma=0.05):\r\n",
        "        super(MAPLoss, self).__init__()\r\n",
        "        self.loss = nn.MSELoss().to(device)\r\n",
        "        self.gamma = gamma\r\n",
        "\r\n",
        "    # D_map_O, D_map_R\r\n",
        "    def __call__(self, D_O, D_R, A_N):\r\n",
        "        Z = Variable(torch.zeros(D_R.shape)).to(device)\r\n",
        "        D_A = self.loss(D_O,A_N)\r\n",
        "        D_Z = self.loss(D_R,Z)\r\n",
        "        return self.gamma * (D_A + D_Z)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}